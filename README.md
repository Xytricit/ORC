# ORC - AI-Powered Codebase Intelligence Platform

<p align="center">
  <img src="assets/orclogo.png" alt="ORC Logo" width="200"/>
</p>

**ORC** (Optimization & Refactoring Catalyst) is a comprehensive AI-powered platform for analyzing, understanding, and optimizing codebases. It combines graph-based analysis, multi-language parsing, and AI insights to provide deep understanding of your code.

> **âœ¨ Latest Update (2026-01-16):** Phase 6 & 7 Complete!
> - âœ… TOC Generator for fast database navigation (50-500x faster)
> - âœ… Complete system integration (parsers â†’ database â†’ TOC â†’ AI)
> - âœ… 19-table knowledge database with semantic detection
> - âœ… All 8 success criteria passed - Production ready!

## ğŸš€ Features

### ğŸ“Š **Multi-Language Support**
- **Python** - Full AST parsing with McCabe complexity
- **JavaScript** - ES6+ and CommonJS support
- **TypeScript** - Interfaces, types, and decorators
- More languages coming soon!

### ğŸ” **Comprehensive Analysis**
- **Semantic Detection** - API endpoints, database queries, error handling, config usage
- **Security Analysis** - SQL injection, hardcoded secrets, XSS risks
- **Dead Code Detection** - Find unused functions and classes
- **Complexity Analysis** - McCabe cyclomatic complexity
- **Dependency Tracking** - Module and function-level dependencies
- **Circular Dependency Detection** - Find problematic imports
- **Coupling Analysis** - Measure module coupling

### ğŸ’¾ **Intelligent Storage**
- **Graph Database** - SQLite-based with 19 tables (expanded!)
- **TOC Navigation** - Keyword-based index for instant lookups
- **Smart Caching** - 47x speedup with TTL caching
- **Batch Processing** - 80,270+ inserts/second
- **AI Backend** - Enhances raw parser data with intelligence

### ğŸ¨ **Professional CLI**
- **8 Commands** - init, index, scan, report, find, check, ignore, config
- **Interactive Chat** - 12 slash commands for AI interaction
- **Syntax Highlighting** - Pygments-powered code display
- **Cross-Platform** - Windows, Mac, Linux support

### ğŸ“ˆ **Performance**
- **Fast Indexing** - 100 files in <5 seconds
- **Parallel Processing** - Auto-detects CPU cores
- **Efficient Caching** - mtime-based invalidation

---

## ğŸ“¦ Installation

### Requirements
- Python 3.8 or higher
- pip package manager

### Install from Source

```bash
# Clone the repository
git clone https://github.com/yourusername/orc.git
cd orc

# Install in development mode
pip install -e .

# Or install with development dependencies
pip install -e .[dev]
```

### Install Dependencies Only

```bash
pip install -r requirements.txt
```

---

## ğŸ¯ Quick Start

### 1. Initialize ORC

```bash
cd your-project
orc init
```

This creates:
- `.orc/` directory
- `orc_config.yaml` configuration file
- `.orcignore` pattern file

### 2. Index Your Project

```bash
orc index
```

Output:
```
â€º Indexing Project
  âœ“ Files indexed: 42
  âœ“ Functions found: 128
  âœ“ Classes found: 18
  âœ“ Imports found: 95
  â€¢ Completed in 3.87s
```

### 3. Run Analysis

```bash
orc scan
```

Quick health check with:
- File statistics
- Function count
- Complexity analysis
- Dead code detection

### 4. Generate Report

```bash
orc report --output analysis.md
```

Creates comprehensive markdown report with all findings.

---

## ğŸ“– CLI Commands

### Core Commands

#### `orc init`
Initialize ORC in current directory
```bash
orc init
```

#### `orc index [--force] [--quiet]`
Index project files
```bash
orc index              # Normal indexing
orc index --force      # Force re-index
orc index --quiet      # Minimal output
```

#### `orc scan`
Quick health scan and analysis
```bash
orc scan
```

#### `orc report [--output FILE]`
Generate comprehensive report
```bash
orc report                    # Print to stdout
orc report --output report.md # Save to file
```

#### `orc find <what>`
Find specific code patterns
```bash
orc find dead       # Find dead code
orc find complex    # Find complex functions (>10)
orc find large      # Find large functions (>200 LOC)
orc find "pattern"  # Search by name pattern
```

#### `orc check`
Health check (no full indexing)
```bash
orc check
```

#### `orc ignore <pattern>`
Add pattern to .orcignore
```bash
orc ignore "*.test.js"
orc ignore "build/"
```

#### `orc config [action]`
Manage configuration
```bash
orc config list              # Show all config
orc config set --key x --value y  # Set value
orc config reset             # Reset to defaults
```

---

## ğŸ¤– AI Integration

ORC integrates with multiple AI providers for code analysis, summarization, and intelligent assistance.

### Supported AI Providers

| Provider | Status | Cost | Speed | Notes |
|----------|--------|------|-------|-------|
| **Groq** | âœ… Free | Free | âš¡ Fast | Recommended for testing |
| **OpenAI** | âœ… Available | $$ | Fast | GPT-4, GPT-3.5 |
| **Anthropic** | âœ… Available | $$ | Medium | Claude 3 (Opus, Sonnet, Haiku) |
| **DeepSeek** | âœ… Available | $ | Fast | Cost-effective |
| **Ollama** | âœ… Available | Free | Medium | Local models |
| **Gemini** | ğŸ”œ Coming Soon | Free tier | Fast | Google AI |

### Setup AI Provider

1. **Get API Key** (for cloud providers):
   ```bash
   # Groq (Recommended for testing - free)
   export GROQ_API_KEY="your-groq-key"
   
   # OpenAI
   export OPENAI_API_KEY="your-openai-key"
   
   # Anthropic
   export ANTHROPIC_API_KEY="your-anthropic-key"
   
   # DeepSeek
   export DEEPSEEK_API_KEY="your-deepseek-key"
   ```

2. **Configure in orc_config.yaml**:
   ```yaml
   ai:
     provider: groq  # or openai, anthropic, deepseek, ollama
     model: null     # null = use default model
     api_key: null   # null = read from environment
   ```

3. **Test AI Integration**:
   ```bash
   python -m pytest orc/tests/test_ai_integration.py -v
   ```

### AI Features

#### 1. Code Summarization
Generate AI summaries for functions and classes:
```python
from orc.ai import AICodeSummarizer

summarizer = AICodeSummarizer(provider='groq')
summary = summarizer.summarize_function(
    function_name='calculate_score',
    function_code='def calculate_score(data): ...'
)
print(summary)
# Output: "Calculates weighted score from input data array"
```

#### 2. Interactive Chat (Coming Soon)
Launch interactive AI chat:
```bash
orc chat
```

### Slash Commands

- `/help` - Show all commands
- `/clear` - Clear history
- `/mode [auto|chat|work]` - Set mode
- `/save [name]` - Save session
- `/load <name>` - Load session
- `/sessions` - List sessions
- `/export [md|json]` - Export conversation
- `/tokens` - Show token usage
- `/cost` - Show estimated cost
- `/exit` - Exit chat

#### 3. AI-Powered Tools
ORC provides 19 tools for AI function calling:
- `query_functions` - Search functions by pattern
- `query_classes` - Search classes
- `get_function_details` - Get full function info
- `get_complexity` - Get complexity metrics
- `find_dead_code` - Find unused code
- `find_circular_deps` - Find circular dependencies
- `get_file_dependencies` - Get file deps
- `query_imports` - Search imports
- And 11 more...

#### 4. Programmatic AI Usage
```python
from orc.ai import AIClient, AIMessage

# Create AI client
client = AIClient(provider='groq')

# Chat with AI
messages = [
    AIMessage(role='system', content='You are a code expert'),
    AIMessage(role='user', content='Explain this function')
]

response = client.chat(messages)
print(response.content)
print(f"Tokens: {response.input_tokens} in, {response.output_tokens} out")
```

### AI Configuration

Default models per provider:
```yaml
groq: llama-3.1-70b-versatile
openai: gpt-4-turbo-preview
anthropic: claude-3-sonnet-20240229
deepseek: deepseek-chat
ollama: llama2
```

Override model in config:
```yaml
ai:
  provider: openai
  model: gpt-3.5-turbo  # Use GPT-3.5 instead of GPT-4
```

### Cost Estimation

ORC tracks token usage and estimates costs:
```bash
orc chat
# ... use AI features ...
/tokens  # Show token usage
/cost    # Show estimated cost
```

**Pricing (per 1M tokens)**:
- Groq: Free
- OpenAI GPT-4: $30 input / $60 output
- OpenAI GPT-3.5: $0.50 input / $1.50 output
- Anthropic Opus: $15 input / $75 output
- Anthropic Sonnet: $3 input / $15 output
- DeepSeek: $0.14 input / $0.28 output
- Ollama: Free (local)

---

## âš™ï¸ Configuration

### Configuration File: `orc_config.yaml`

```yaml
# Project Configuration
project_root: .
db_path: .orc/graph.db
cache_dir: .orc/cache
sessions_dir: .orc/sessions

# AI Configuration (Coming Soon)
ai:
  provider: groq
  model: null
  api_key: null

# Analysis Thresholds
analysis:
  max_complexity_threshold: 10
  max_coupling_threshold: 0.7
  dead_code_confidence: 0.8

# Performance
parallel:
  workers: null      # Auto-detect CPU count
  cache_ttl: 3600    # Cache TTL in seconds

# Ignore Patterns (in addition to .orcignore)
ignored_patterns:
  - __pycache__
  - .git
  - node_modules
  - dist
  - build
```

### Ignore File: `.orcignore`

Similar to `.gitignore` syntax:
```
__pycache__/
*.pyc
.git/
node_modules/
dist/
build/
.env
```

---

## ğŸ—ï¸ Architecture

### Component Overview

```
orc/
â”œâ”€â”€ core/           # Indexing & caching (Component 1)
â”œâ”€â”€ storage/        # Database & persistence (Component 2)
â”œâ”€â”€ parsers/        # Language parsers (Component 3)
â”œâ”€â”€ ai/             # AI integration (Component 4)
â”œâ”€â”€ analysis/       # Code analysis (Component 5)
â”œâ”€â”€ cli/            # CLI commands (Component 7)
â””â”€â”€ session/        # Session management (Component 7)
```

### Database Schema

10 tables with 7 performance indexes:
1. `file_index` - Indexed files
2. `function_index` - Functions with complexity
3. `class_index` - Classes with inheritance
4. `import_index` - Import statements
5. `export_index` - Exported entities
6. `file_dependencies` - File-to-file deps
7. `function_calls_resolved` - Call graph
8. `entry_points` - Application entry points
9. `code_summaries` - AI summaries
10. `ai_insights` - AI analysis results

---

## ğŸ§ª Testing

### Run Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=orc --cov-report=html

# Run specific test file
pytest tests/test_parsers.py

# Run with verbose output
pytest -v
```

### Test Statistics

- **61+ tests** for Component 7 (CLI)
- **77 tests** for Component 1 (Indexing)
- **25 tests** for Component 2 (Database)
- **29 tests** for Component 3 (Parsers) 
- **31 tests** for Component 5 (Analysis)
- **13 tests** for Component 4 (AI Integration)
- **25 tests** for Database (19 tables)
- **7 tests** for AI Backend
- **5 tests** for TOC Generator
- **Total: 189+ tests** (100% passing)

---

## ğŸ“Š Performance Benchmarks

| Operation | Performance |
|-----------|-------------|
| Indexing (100 files) | 3.87s |
| Database Inserts | 80,270/sec |
| Analysis | 71,895 funcs/sec |
| Cache Speedup | 47x faster |

---

## ğŸ› ï¸ Development

### Project Structure

```
orc/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ parallel_indexer.py
â”‚   â”œâ”€â”€ index_service.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ cache.py
â”œâ”€â”€ storage/
â”‚   â””â”€â”€ graph_db.py
â”œâ”€â”€ parsers/
â”‚   â”œâ”€â”€ all_parsers.py
â”‚   â”œâ”€â”€ python_parser.py
â”‚   â”œâ”€â”€ javascript_parser.py
â”‚   â””â”€â”€ typescript_parser.py
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ all_analyzers.py
â”‚   â”œâ”€â”€ analyzer.py
â”‚   â”œâ”€â”€ dependency_resolver.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ cli_main.py
â”‚   â”œâ”€â”€ cli_loop.py
â”‚   â”œâ”€â”€ cli_style.py
â”‚   â””â”€â”€ ui_components.py
â””â”€â”€ session/
    â”œâ”€â”€ session_manager.py
    â””â”€â”€ token_tracker.py
```

### Adding New Parsers

```python
from orc.parsers import BaseParser, register_parser

class MyParser(BaseParser):
    def parse_file(self, path):
        # Your parsing logic
        return {
            'files': {...},
            'functions': {...},
            'classes': {...},
            'imports': {...},
        }

# Register the parser
register_parser('.myext', MyParser)
```

---

## ğŸ“ Examples

### Example 1: Analyze a Python Project

```bash
cd my-python-project
orc init
orc index
orc find complex
```

### Example 2: Find Dead Code

```bash
orc scan
orc find dead
```

### Example 3: Generate Full Report

```bash
orc report --output analysis.md
cat analysis.md
```

### Example 4: Programmatic Usage

```python
from orc import ParallelIndexer, GraphDB, Analyzer

# Index project
indexer = ParallelIndexer(root_path='.')
result = indexer.index()

# Query database
db = GraphDB('.orc/graph.db')
functions = db.query_functions()

# Run analysis
analyzer = Analyzer()
analysis = analyzer.run_all(result)

print(f"Dead code: {len(analysis['dead_code'])} items")
print(f"Complex functions: {len(analysis['complexity'])} items")
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Clone repository
git clone https://github.com/yourusername/orc.git
cd orc

# Install in development mode with dev dependencies
pip install -e .[dev]

# Run tests
pytest

# Run with coverage
pytest --cov=orc
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

Built with:
- **Click** - CLI framework
- **NetworkX** - Graph analysis
- **Pygments** - Syntax highlighting
- **prompt-toolkit** - Interactive prompts

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/orc/issues)
- **Documentation**: [Full Docs](https://orc-docs.example.com)

---

## ğŸ—ºï¸ Roadmap

- [x] Core indexing system
- [x] Multi-language parsers
- [x] Database storage
- [x] Analysis modules
- [x] CLI interface
- [x] AI integration (multi-provider)
- [ ] Interactive AI chat (in progress)
- [ ] Web dashboard
- [ ] VS Code extension
- [ ] More language support (Go, Rust, Java)

---

**ORC** - Making codebases intelligent, one analysis at a time. ğŸš€
