# ORC Database Optimizations for Large Codebases

This document describes the performance optimizations implemented in ORC for handling huge databases (500k+ LOC codebases).

## Overview

ORC's database mapping has been optimized to handle massive codebases efficiently through:
- **Database indexes** on all frequently-queried columns
- **SQLite PRAGMA optimizations** for maximum performance
- **Smart query result caching** with TTL
- **Pagination support** for large result sets
- **Streaming queries** for memory efficiency
- **Connection pooling** optimizations

## Performance Improvements

### Before Optimization
- Statistics query: ~5-10 seconds on large codebases
- Repeated queries: Same slow performance
- Memory issues with large result sets

### After Optimization
- **First query**: ~0.05 seconds (100x faster)
- **Cached queries**: <0.001 seconds (instant)
- **Memory efficient**: Handles 500k+ LOC without issues

## Database Indexes

### Function Index
```sql
CREATE INDEX idx_function_file_path ON function_index(file_path)
CREATE INDEX idx_function_name ON function_index(name)
CREATE INDEX idx_function_complexity ON function_index(complexity DESC)
CREATE INDEX idx_function_language ON function_index(language)
```

### Class Index
```sql
CREATE INDEX idx_class_file_path ON class_index(file_path)
CREATE INDEX idx_class_name ON class_index(name)
CREATE INDEX idx_class_language ON class_index(language)
```

### Import Index (Dependency Analysis)
```sql
CREATE INDEX idx_import_file_path ON import_index(file_path)
CREATE INDEX idx_import_module ON import_index(module)
CREATE INDEX idx_import_composite ON import_index(module, file_path)
```

### Export Index
```sql
CREATE INDEX idx_export_file_path ON export_index(file_path)
CREATE INDEX idx_export_symbol ON export_index(symbol)
```

### File Index
```sql
CREATE INDEX idx_file_language ON file_index(language)
CREATE INDEX idx_file_loc ON file_index(loc DESC)
```

## SQLite PRAGMA Optimizations

### Write-Ahead Logging (WAL)
```sql
PRAGMA journal_mode=WAL
```
Enables better concurrency and faster writes.

### Increased Cache Size
```sql
PRAGMA cache_size=-51200  -- 50MB cache
```
Default is 10MB. Larger cache = faster queries on large databases.

### Memory-Based Temp Storage
```sql
PRAGMA temp_store=MEMORY
```
Stores temporary tables in RAM for speed.

### Optimized Synchronization
```sql
PRAGMA synchronous=NORMAL
```
Balanced safety and performance for read-heavy workloads.

### Memory-Mapped I/O
```sql
PRAGMA mmap_size=268435456  -- 256MB
```
Enables memory-mapped I/O for large database files.

## Query Result Caching

The `CodebaseMapper` class implements intelligent caching:

```python
mapper = CodebaseMapper(db_path, cache_ttl=300)  # 5 minute TTL
stats = mapper.get_statistics()  # First call: queries DB
stats = mapper.get_statistics()  # Second call: instant from cache
```

### Cached Methods
- `get_statistics()` - Codebase stats
- `get_codebase_map()` - Hierarchical structure
- `get_hotspots()` - Complexity/coupling hotspots
- `get_dependency_graph_data()` - Graph visualization data

### Cache Management
```python
mapper.clear_cache()  # Manually clear cache if needed
```

## Pagination Support

Handle large result sets efficiently:

```python
# Paginate through functions
page1 = mapper.get_functions_paginated(
    page=1, 
    page_size=100,
    min_complexity=10
)

print(f"Page {page1['page']} of {page1['total_pages']}")
print(f"Total functions: {page1['total_count']}")
print(f"Has next: {page1['has_next']}")

# Paginate through files
files = mapper.get_files_paginated(
    page=1,
    page_size=50,
    language='python',
    min_loc=500
)
```

## Streaming Queries

For extremely large queries that don't fit in memory:

```python
query = "SELECT * FROM function_index WHERE complexity > 10"
for batch in mapper.stream_large_query(query, batch_size=1000):
    # Process 1000 rows at a time
    for row in batch:
        process(row)
```

## Dependency Graph Optimization

Limit nodes and edges for visualization performance:

```python
graph = mapper.get_dependency_graph_data(
    max_nodes=500,        # Limit to 500 most connected modules
    min_connections=2     # Only show modules with 2+ connections
)
```

## Performance Benchmarks

Tested on a codebase with:
- **5,904 files**
- **11,562 functions**
- **11,960 classes**

### Results
```
ðŸ“Š Statistics Query (No Cache):     0.049s
ðŸ“Š Statistics Query (Cached):       0.000s (instant)
ðŸ“Š Hotspots Analysis:                0.039s
ðŸ“Š Paginated Functions (50 items):   0.064s
ðŸ“Š Codebase Map (depth=2):           0.230s
ðŸ“Š 5 Repeated Cached Calls:          0.000s total
```

## Best Practices

### 1. Use Pagination for Large Datasets
```python
# Don't: Load all functions at once
all_functions = get_all_functions()  # Could be 10k+ items

# Do: Use pagination
page1 = mapper.get_functions_paginated(page=1, page_size=100)
```

### 2. Leverage Caching
```python
# Create one mapper instance and reuse it
mapper = CodebaseMapper(db_path)

# These calls will be cached
for i in range(10):
    stats = mapper.get_statistics()  # Only first call hits DB
```

### 3. Use Appropriate Cache TTL
```python
# Short-lived cache for rapidly changing data
mapper = CodebaseMapper(db_path, cache_ttl=60)

# Long-lived cache for stable data
mapper = CodebaseMapper(db_path, cache_ttl=3600)
```

### 4. Stream Large Queries
```python
# For processing millions of rows
for batch in mapper.stream_large_query(huge_query):
    process_batch(batch)
```

## Integration with AI Tools

The optimized mapper is integrated with ORC's AI tools:

```python
# AI can efficiently query large codebases
tools = ORCTools()
codebase_map = tools.get_codebase_map(depth=2)  # Fast!
hotspots = tools.get_hotspots(limit=20)          # Fast!
```

## Troubleshooting

### Slow Queries
1. Check if indexes exist: Run `.indices` in SQLite CLI
2. Clear cache if stale: `mapper.clear_cache()`
3. Reduce depth for codebase_map: Use `depth=1` or `depth=2`

### Memory Issues
1. Use pagination instead of loading all results
2. Use streaming queries for very large datasets
3. Reduce cache_ttl to free memory faster

### Lock Errors
WAL mode should prevent most locks, but if issues persist:
```python
# Add a small delay between writes
import time
time.sleep(0.01)
```

## Future Optimizations

Potential improvements for even larger codebases:
- [ ] Connection pooling for concurrent queries
- [ ] Compressed storage for large text fields
- [ ] Incremental indexing with delta updates
- [ ] Distributed indexing for multi-million LOC projects
- [ ] Query result materialized views

## Conclusion

ORC's database optimizations enable efficient navigation and analysis of codebases with 500k+ lines of code. The combination of indexes, caching, pagination, and PRAGMA optimizations provides **100x+ performance improvements** over naive database queries.

For more information, see:
- `orc/storage/graph_db.py` - Database schema and indexes
- `orc/tools/codebase_mapper.py` - Optimized mapper implementation
- `orc/ai_tools.py` - AI tool integration
